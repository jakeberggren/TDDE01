# fit <- tree(y ~ ., data = test, method = "class")
losses <- pred_test%*%matrix(c(0,5,1,0), nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
pred <- levels(test$y)[best_i]
table(pred, test$y)
# fit <- tree(y ~ ., data = test, method = "class")
prob <- predict(opt_tree, newdata = test)
losses <- pred_test%*%matrix(c(0,5,1,0), nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
pred <- levels(test$y)[best_i]
table(pred, test$y)
# fit <- tree(y ~ ., data = test, method = "class")
prob <- predict(opt_tree, newdata = test)
losses <- pred_test%*%matrix(c(0,5,1,0), nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
pred <- levels(test$y)[best_i]
table(pred, test$y)
# fit <- tree(y ~ ., data = test, method = "class")
prob <- predict(opt_tree, newdata = test)
losses <- prob%*%matrix(c(0,5,1,0), nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
pred <- levels(test$y)[best_i]
table(pred, test$y)
# Alternative 1
prob <- predict(opt_tree, newdata = test)
losses <- prob%*%matrix(c(0,1,5,0), byrow = TRUE, nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
pred <- levels(test$y)[best_i]
table(pred, test$y)
source("~/Desktop/Git/github/tdde01/lab2/assigment_1.R")
plot(test$Fat, col = "blue")
points(cv_pred)
points(cv_pred, col = "red")
plot(test$Fat, col = "blue", ylim = c(0, 100))
points(cv_pred, col = "red")
plot(test$Fat, col = "blue", ylim = c(0, 60))
points(cv_pred, col = "red")
source("~/Desktop/Git/github/tdde01/lab2/assigment_1.R", echo=TRUE)
coef(cv, s = "lambda.min")
summary(cv)
view(summary(cv))
plot(test$Fat, col = "blue", ylim = c(0, 60), ylab = "Fat levels")
points(cv_pred, col = "green")
legend("topright", c("actuals", "predicted using cross validation"),
fill = c("blue", "green"))
plot(test$Fat, col = "blue", ylim = c(0, 60), ylab = "Fat levels",
main = "Original test vs model with optimal lamdbda")
points(cv_pred, col = "green")
legend("topright", c("actuals", "predicted using cross validation"),
fill = c("blue", "green"))
source("~/Desktop/Git/github/tdde01/lab2/assigment_1.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_1.R")
data <- read.csv("data/communities.csv")
data <- read.csv("data/communities.csv")
View(data)
data <- read.csv("data/communities.csv", header = FALSE)
View(data)
data <- read.csv("data/communities.csv")
data <- read.csv2("data/communities.csv")
View(data)
data <- read.csv("data/communities.csv")
View(data)
########### Libraries #############
library(caret)
data <- (cbind(scale(select(data, -ViolentCrimesPerPop)), ViolentCrimesPerPop))
library(dplyr)
scaler=preProcess(data, -ViolentCrimesPerPop)
########### Libraries #############
library(caret)
library(dplyr)
data <- read.csv("data/communities.csv")
scaler=preProcess(data, -ViolentCrimesPerPop)
trainS=predict(scaler,train)
View(data)
scaler=preProcess(data, -data$ViolentCrimesPerPop)
scaler=preProcess(data, -data$ViolentCrimesPerPop)
# Reading and scaling data
data <- read.csv("data/communities.csv")
scaler=preProcess(data, -ViolentCrimesPerPop)
data <- predict(scaler, data)
scaler=preProcess(data %>% select(-ViolentCrimesPerPop))
data <- predict(scaler, data)
View(data)
# Reading and scaling data
data <- read.csv("data/communities.csv")
data <- scale(data %>% select(-ViolentCrimesPerPop))
View(data)
# Reading and scaling data
data <- read.csv("data/communities.csv")
scaler <- preProcess(data %>% select(-ViolentCrimesPerPop))
data <- predict(scaler, data)
# PCA
eigen <- eigen(data)
# PCA
res <- prcomp(data)
View(res)
eigen(res)
cov <- <- cov(data)
cov <- cov(data)
eigen(cov)
eigen(cov)
eigen_val <- eigen(cov)
# PCA using princomp
res2 <- princomp(data)
View(res2)
View(res)
View(res2)
View(res)
View(res2)
View(res)
View(res2)
View(res2)
res2
plot(res2)
plot(res2$sdev)
plot(res2)
View(res2)
res2[["loadings"]]
res2[["loadings"]][0]
res2[["loadings"]][1]
res2[["loadings"]][[comp.1]]
res2[["loadings"]][["comp.1"]]
res2[["loadings"]]$comp.1
res2[["loadings"]][["Comp.1"]]
res2[["loadings"]]
res2[["loadings"]]
res2[["loadings"]][,1]
plot(res2[["loadings"]][,1])
plot(res2[["loadings"]][,1], type = "b")
plot(res2[["loadings"]][,1], type = "p")
plot(res2[["loadings"]][,1], col = "blue")
plot(res2[["loadings"]][,1], col = "green")
plot(res2[["loadings"]][,1], col = "green",
main = "Trace plot of first principle componente")
plot(res2[["loadings"]][,1], col = "green",
main = "Trace plot of first principle component")
plot(res2[["loadings"]][,1], col = "green", pca = 20
main = "Trace plot of first principle component", ylab = )
plot(res2[["loadings"]][,1], col = "green", pca = 20,
main = "Trace plot of first principle component", ylab = )
?plot
plot(res2[["loadings"]][,1], col = "green", pch = 20,
main = "Trace plot of first principle component", ylab = )
plot(res2[["loadings"]][,1], col = "green", pch = 18,
main = "Trace plot of first principle component", ylab = )
plot(res2[["loadings"]][,1], col = "green",
main = "Trace plot of first principle component", ylab = )
library(ggplot2)
res2
cm_fit <- table(predict_fit ,test$y)
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
cm_fit <- table(predict_fit ,test$y)
cm_fit
cm_fit
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
cm_fit
########### Libraries #############
library(dplyr)
library(tidyr)
library(tree)
library(MLmetrics)
library(caret)
library(rpart)
library(rpart.plot)
data <- read.csv("data/bank-full.csv", sep = ";", stringsAsFactors = TRUE)
data <- data %>% select(-duration)
# data partition
n <- dim(data)[1]
set.seed(12345)
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
id3 <- setdiff(id1, id2)
test <- data[id3, ]
# Computing trees with settings a, b and c
tree_a <- tree(y ~ ., data = train)
tree_b <- tree(y ~ .,
data = train,
control = tree.control(nrow(train), minsize = 7000)
)
tree_c <- tree(y ~ .,
data = train,
control = tree.control(nrow(train), mindev = 0.0005)
)
# Predictions on validation set
pred_a <- predict(tree_a, newdata = valid, type = "class")
pred_b <- predict(tree_b, newdata = valid, type = "class")
pred_c <- predict(tree_c, newdata = valid, type = "class")
# Summaries to report misclassification rate for trees on train set.
summary(tree_a) # 0.1048
summary(tree_b) # 0.1048
summary(tree_c) # 0.09362
# Calculating misclassification rate for validation data
misclass_valid_a <- mean(pred_a != valid$y)
misclass_valid_b <- mean(pred_b != valid$y)
misclass_valid_c <- mean(pred_c != valid$y)
# Print validation misclass
data.frame(
a = misclass_valid_a,
b = misclass_valid_b,
c = misclass_valid_c
)
train_score <- rep(0, 50)
valid_score <- rep(0, 50)
# Find optimal number of leaves.
for (i in 2:50) {
pruned_tree <- prune.tree(tree_c, best = i)
valid_pred <- predict(pruned_tree, newdata = valid, type = "tree")
train_score[i] <- deviance(pruned_tree)
valid_score[i] <- deviance(valid_pred)
}
# Visualize with plot
plot(2:50, train_score[2:50],
type = "b", col = "red", ylim = c(8000, 12000),
main = "Optimal tree depth", ylab = "Deviance", xlab = "Number of leaves"
)
points(2:50, valid_score[2:50], type = "b", col = "blue")
legend("topright", c("train data", "validation data"), fill = c("red", "blue"))
# Optimal number of leaves
opt_train <- which.min(train_score[-1])
opt_valid <- which.min(valid_score[-1])
data.frame(train = opt_train + 1,
valid = opt_valid + 1)
opt_tree <- prune.tree(tree_c, best = 22) # vad är bästa träddjupet?
# visualization of tree structure with optimal number of leaves
plot(opt_tree)
opt_tree
pred_test <- predict(opt_tree, newdata = test, type = "class")
# Confusion matrix
confusion_matrix <- table(pred_test, test$y)
conf_matrix <- confusionMatrix(pred_test, test$y)
# Using MLmetrics to estimate accuracy and F1 score.
Accuracy(pred_test, test$y) # 0.891035, accuracy for no
F1_Score(pred_test, test$y) # 0.9414004
# Manuel f1 for yes.
f1 <- 2*tp/(2*tp + fp + fn) # 0.224554, f1 score for yes
# Alternative 1
prob <- predict(opt_tree, newdata = test)
losses <- prob%*%matrix(c(0,1,5,0), byrow = TRUE, nrow=2)
best_i <- apply(losses, MARGIN = 1, FUN = which.min)
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
cm_fit <- table(predict_fit ,test$y)
cm_fit
table(pred, test$y)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
ggplot(res2)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
ggplot(res2)
library(ggfortify)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
ggfortify(res2)
library(ggfortify)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
ggfortify(res2)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
ggplot(res2)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2)
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color(as.facotr(ViolentCrimesPerPop)))
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color = as.factor(ViolentCrimesPerPop))
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color = as.factor(ViolentCrimesPerPop)) +
scale_color_manual("deepskyblue2")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color = as.factor(ViolentCrimesPerPop)) +
scale_color_manual("deepskyblue2")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color = as.factor(data$ViolentCrimesPerPop)) +
scale_color_manual("deepskyblue2")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color = as.factor(data$ViolentCrimesPerPop))
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, aes(color = as.factor(data$ViolentCrimesPerPop)))
?ggfortify
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, ViolentCrimesPerPop.color('blue'))
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop.color")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, color="ViolentCrimesPerPop")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour=as.factor("ViolentCrimesPerPop"))
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour=as.factor(ViolentCrimesPerPop))
u
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color="Violent crimes per pop")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color="Violent crimes per pop.
")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color="Violent crimes per pop.")
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
cm_fit
table(pred, test$y)
predict_fit
as.matrix(predict_fit)
train
view(test)
View(test)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color="Violent crimes per pop.")
source("~/Desktop/Git/github/tdde01/lab2/assigment_2.R")
predict_fit
cm_fit
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
# plot of the PC scores. Color of points is given by ViolentCrimesPerPop
autoplot(res2, colour="ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color="Violent crimes per pop.")
scaled_train <- predict(scaler, train)
model <- lm(ViolentCrimesPerPop~., data = scaled_train)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
model <- lm(ViolentCrimesPerPop~., data = scaled_train)
summary(model)
pred_train <- predict(model, type = "response")
pred_test <- predict(model, newdata = scaled_test, type = "response")
mse_train <- mean((scaled_train$ViolentCrimesPerPop - pred_train)^2)
mse_test <- mean((scaled_test$ViolentCrimesPerPop - pred_test)^2)
View(test)
View(scaled_test)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt <- optim(theta = rep(0, 100), fn = cost, method = "BFGS")
opt <- optim(par = rep(0, 100), fn = cost, method = "BFGS")
scaled_test %>% select(-ViolentCrimesPerPop)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
View(opt)
multi_mean
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
multi_mean
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
multi_mean
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
multi_mean
opt <- optim(par = rep(0, 100), fn = cost, method = "BFGS")
print(multi_mean)
plot(multi_mean)
multi_mean = c()
cost <- function(theta) {
x <- as.matrix(scaled_test %>% select(-ViolentCrimesPerPop))
mean <- mean(scaled_test$ViolentCrimesPerPop - x*theta)^2
multi_mean <<- append(mean)
return(mean)
}
opt <- optim(par = rep(0, 100), fn = cost, method = "BFGS")
multi_mean = c()
cost <- function(theta) {
x <- as.matrix(scaled_test %>% select(-ViolentCrimesPerPop))
mean <- mean(scaled_test$ViolentCrimesPerPop - x*theta)^2
multi_mean <<- c(multi_mean,mean)
return(mean)
}
opt <- optim(par = rep(0, 100), fn = cost, method = "BFGS")
plot(multi_mean)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
multi_mean = c()
cost <- function(theta) {
x <- as.matrix(scaled_test %>% select(-ViolentCrimesPerPop))
mean <- mean((scaled_test$ViolentCrimesPerPop - x*theta)^2)
multi_mean <<- c(multi_mean,mean)
return(mean)
}
opt <- optim(par = rep(0, 100), fn = cost, method = "BFGS")
plot(multi_mean)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
multi_mean
as.matrix(scaled_test %>% select(-ViolentCrimesPerPop))
as.matrix(scaled_test %>% select(-ViolentCrimesPerPop))
plot(multi_mean[500:length(multi_mean)])
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
scaled_train$ViolentCrimesPerPop
as.matrix(scaled_train %>% select(-ViolentCrimesPerPop))
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
plot(multi_mean_train)
plot(multi_mse_train)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
plot(multi_mse_train[500:20114])
plot(multi_mse_train[5000:20114])
length(multi_mse_train)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
points(multi_mse_test[5000:length(multi_mse_test)])
points(multi_mse_test[5000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[5000:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[5000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
points(multi_mse_test[5000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[5000:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[5000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[2000:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[2000:length(multi_mse_test)], col = 'green')
points(multi_mse_test[2000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[2000:length(multi_mse_train)], col = 'blue')
points(multi_mse_test[2000:length(multi_mse_test)], col = 'green')
points(multi_mse_test[2000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train, col = 'blue')
points(multi_mse_test, col = 'green')
plot(multi_mse_train, col = 'blue')
points(multi_mse_test, col = 'green')
plot(multi_mse_train[2000:length(multi_mse_train)], col = 'blue', ylim = c(0.07, 0.09))
points(multi_mse_test[2000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue', ylim = c(0.07, 0.09))
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[1000:length(multi_mse_train)], col = 'blue', ylim = c(0.02, 0.09))
points(multi_mse_test[1000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[1000:length(multi_mse_train)], col = 'blue', ylim = c(0.06, 0.09))
points(multi_mse_test[1000:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue', ylim = c(0.06, 0.09))
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue', ylim = c(0.06, 0.2))
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue', ylim = c(0.06, 0.1))
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:8000], col = 'blue', ylim = c(0.06, 0.1))
points(multi_mse_test[500:8000], col = 'green')
length(multi_mse_train)
length(multi_mse_train)
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue', ylim = c(0.06, 0.1))
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:length(multi_mse_train)], col = 'blue',
ylim = c(0.06, 0.1), ylab = "Mean square error", xlab = "# of iterations")
points(multi_mse_test[500:length(multi_mse_test)], col = 'green')
plot(multi_mse_train[500:12000], col = 'blue',
ylim = c(0.06, 0.1), ylab = "Mean square error", xlab = "# of iterations")
points(multi_mse_test[500:12000], col = 'green')
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
opt_iteration <- which.min(multi_mse_test)
opt_iteration
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
multi_mse_test[2166]
plot(multi_mse_train[0:7000], col = 'blue',
ylim = c(0.06, 0.1), ylab = "Mean square error", xlab = "# of iterations",
main = "pooperscooper")
points(multi_mse_test[0:700], col = 'green')
points(multi_mse_test[0:7000], col = 'green')
point(opt_iteration)
points(opt_iteration)
points(opt_iteration, multi_mse_test[opt_iteration])
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
multi_mse_test[2182]
multi_mse_test[2166]
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
?glm
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
multi_mse_test
View(scaled_test)
sum(scaled_train)
View(scaled_train)
sum(train)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
opt_iteration
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
sum(train)
sum(scaled_train)
sum(scaled_test)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
sum(scaled_test)
source("~/Desktop/Git/github/tdde01/lab2/assigment_3.R")
sum(scaled_train)
sum(scaled_test)
